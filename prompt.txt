You will be given the content of a newly published arXiv paper and asked to write a summary of it.

Here are some things to keep in mind:
- Summarize the paper in a way that is understandable to the general public
- Use a professional tone
- Don't use the word "quest" or similar flowerly language
- Don't say this is a recent paper, since this summary may be referenced in the future
- Limit your summary to about 4 paragraphs
- Do not prefix the article with a title
- Do not mention the author's names
- You can use the following markdown tags in your summary: ordered list, unordered list, and h3 headings
- Divide the summary into sections using markdown h3 headings
- Do not include a title for the summary; only include headings to divide the summary into sections
- The first line should be an h3 heading as well.
- Assume readers knows what common AI acronyms stand for like LLM and AI
- Don't mention any part of this prompt

Here's the paper:

---

Taking the Next Step with Generative Artificial Intelligence: The Transformative Role of Multimodal Large Language Models in Science Education

Abstract

The integration of Artificial Intelligence (AI), particularly Large Language Model (LLM)-based systems, in education has shown promise in enhancing teaching and learning experiences. However, the advent of Multimodal Large Language Models (MLLMs) like GPT-4 with vision (GPT-4V), capable of processing multimodal data including text, sound, and visual inputs, opens a new era of enriched, personalized, and interactive learning landscapes in education. Grounded in theory of multimedia learning, this paper explores the transformative role of MLLMs in central aspects of science education by presenting exemplary innovative learning scenarios. Possible applications for MLLMs could range from content creation to tailored support for learning, fostering competencies in scientific practices, and providing assessment and feedback. These scenarios are not limited to text-based and uni-modal formats but can be multimodal, increasing thus personalization, accessibility, and potential learning effectiveness. Besides many opportunities, challenges such as data protection and ethical considerations become more salient, calling for robust frameworks to ensure responsible integration. This paper underscores the necessity for a balanced approach in implementing MLLMs, where the technology complements rather than supplants the educator’s role, ensuring thus an effective and ethical use of AI in science education. It calls for further research to explore the nuanced implications of MLLMs on the evolving role of educators and to extend the discourse beyond science education to other disciplines. Through the exploration of potentials, challenges, and future implications, we aim to contribute to a preliminary understanding of the transformative trajectory of MLLMs in science education and beyond.

1. Introduction

Science education encompasses a broad spectrum of activities, from acquiring scientific knowledge and engaging in scientific practices to effective communication about scientific findings and ideas (US: NRC, (2012)). These competencies are designed to prepare students for the complex, multifaceted challenges they will encounter in today’s world (OECD,, 2018) and, therefore, are often part of 21st-century skills frameworks (e.g., Kay and Dardis, (2016); for science education: McComas, (2014)).
The essence of science learning is inherently multimodal. It necessitates that students engage in a range of activities within different modalities: reading and writing scientific texts, interpreting diagrams, drawing models, flowcharts, and diagrams, analyzing and visualizing data, designing solutions, synthesizing information across various modalities, and communicating scientific ideas. These activities shape the understanding of scientific knowledge and the development of appropriate domain-specific competencies (Lemke,, 1998; Van Leeuwen and Kress,, 1990; Doran et al.,, 2021). Additionally, it requires students to seamlessly shift between these different modes. Representations such as images, graphics, tables, technical symbols, formulas, equations, process workflows, graphs, and video as well as audio data, are used in the learning process. This multimodal nature of science learning demands science educators to facilitate learning with multimodal materials and provide students with opportunities to engage in multimodal activities.

Beyond the multimodal nature of science itself, the general effectiveness of multimodal learning can serve as a second argument for fostering multimodality in science education.
”Multimodal learning” (as defined and used herein) has a cognitive foundation based on the multimedia learning theory (CTML) posited by Mayer (e.g., Mayer, (1997, 2021)). Combining multimodal representations like text and images can enhance knowledge acquisition, improving hence the integration into a coherent multi-faceted mental model. Schnotz and Bannert, (2003) have provided strong evidence for multimodal approaches in (science) education and state, in accordance with (Mayer,, 1997), that learning with multimodal material is highly effective. The real-time generation of multimodal material offers many opportunities for adaptive learning.
Therefore, multimodality is not only an integral part of science education itself but, from the perspective of cognitive science, can be harnessed to build effective learning environments.

With the latest advances in Artificial Intelligence (AI), specifically in generative AI, Large Language Models (LLMs) have become increasingly popular in the general educational context (cf. Seßler et al., (2023); Moore et al., (2022); Abdelghani et al., 2023a ) and science education (cf. Bewersdorff et al., 2023a ; Küchemann et al., (2023)), with strong potential to advance multimodal learning. The use of LLMs in education has grown mainly due to their ability to reason about, generate, and manipulate text data. Since LLMs merely focus on the textual mode, they generally do not capture the variety of multimodal representations in science. With the emergence of Multimodal Large Language Models (MLLMs), we are now able to meet the necessity for multimodality in science education. Educators are able to use MLLM, such as GPT-4V, to read scoring rubrics and grade students’ drawn models (Lee and Zhai,, 2023). MLLMs can process and create content not only in text but across multiple forms of data, including images, audio, and video (Bommasani et al.,, 2021). They can also transform unstructured data into structured content and vice versa (Borisov et al., 2022b, ). This shift from text-centric approaches towards multimodal content generation opens a new era in science education, where the capabilities of LLMs are expanded to meet the multimodal demands of science education.

In this article, we articulate the potential of MLLMs, specifically in the field of science education. Building upon prior research on LLMs in education (e.g., Kasneci et al., (2023); Zhai, (2023); Lee et al., 2023b ) we assess the potential of MLLMs in generally reshaping educational processes. Guided by Mayer’s CTML, we explore the potential of MLLMs in exemplary scenarios of multimodality in instructional strategies and design, student engagement, assessment, and feedback. We will also discuss the challenges related to implementing and applying MLLMs in the classroom, such as data protection and ethical concerns, which become even more pressing with multimodal systems. These multimodal systems are potentially capable of processing not only (mostly) anonymous textual data but also, depending on the specific use cases, personal data like voice recordings or images of handwriting. Tackling these issues is crucial to responsibly integrating MLLMs in learning environments and fully realizing their potential to improve education (Lee et al., 2023b, ).

2. Framework

2.1. Core Elements of Science Education

Science education is crucial in preparing informed citizens capable of navigating an increasingly complex world (OECD,, 2018). This education involves imparting a comprehensive understanding of core scientific concepts and crosscutting ideas essential for building a solid foundation in science (NRC,, 2012). Alongside this robust content knowledge, the development of scientific thinking and practical skills is critical. Engaging students in scientific inquiry and hands-on investigations not only cultivates their critical thinking but also equips them with practical abilities essential for scientific practices (Bybee,, 1997; Flick,, 1993). Moreover, such an approach may also foster their creativity, enabling them to devise effective solutions for ill-structured problems (Hathcock et al.,, 2015). Central to science education is also the emphasis on effective communication skills. Students should be able to articulate and communicate complex scientific ideas with clarity and precision (NRC,, 2012). This significance was particularly highlighted during the recent COVID-19 pandemic, where the adept communication of scientific results played a crucial role in informing the public and guiding decision-making processes in policy-making institutions (Besançon et al.,, 2021).

Central tasks for educators are creating engaging content and empowering students’ learning. In science education, the latter involves not only fostering the acquisition of content knowledge but also encouraging engagement in scientific practices and the communication of scientific findings, insights, and ideas. Assessment and providing effective feedback is a third crucial task of educators. These three central aspects of science education will guide the presentation of the exemplary potentials of MLLMs in chapter 3.

2.2. Large Generative AI Models

Large Language Models. LLMs are a subset of AI models focusing on processing and generating human-like text, enabling thus a wide range of applications from content creation to problem-solving (Brown et al.,, 2020). Those deep learning architectures are characterized by their ability to understand context, generate coherent responses, and provide textual content in real-time.

Incorporating human feedback through the training of reward models and applying reinforcement learning in the fine-tuning step (Ouyang et al.,, 2022; Lee et al., 2023c, ) has significantly enhanced the generation of human-like language that is aligned with social norms and goals and has led to the success of today’s popular language models by OpenAI, ChatGPT and GPT-4 (OpenAI,, 2023). The PaLM models (Chowdhery et al.,, 2022; Anil et al.,, 2023) from Google are setting a focus on a smaller and denser architecture, achieving similar performance. Also, in the open-source landscape, there are strong competitors like Meta’s LLaMA model (Touvron et al., 2023a, ; Touvron et al., 2023b, ), and the Falcon-40B architecture (Penedo et al.,, 2023). These models have sparked further development, with researchers fine-tuning them and creating open-source variants like Vicuna (Zheng et al.,, 2023) and Alpaca (Taori et al.,, 2023).

The impact of these LLMs has been profound and led to novel advances across various industries. They have enabled innovative approaches in areas such as healthcare (Chintagunta et al.,, 2021; Enarvi et al.,, 2020), finance (Dowling and Lucey,, 2023), journalism (Pavlik,, 2023), creative writing (Yuan et al.,, 2022), and even in scientific discovery (Romera-Paredes et al.,, 2023), demonstrating the strength and versatility of LLMs. The advances in the generation of human-like texts have opened up new opportunities and challenges in different domains (Kaddour et al.,, 2023). This includes a meaningful and constructive application in educational contexts, considering remaining issues like correct mathematical reasoning (Imani et al., 2023a, ), or possible hallucinations in the output (Ji et al., 2023a, ). Research continues to address these challenges while also improving their explainability to increase trust and reliability in the model outputs (Wu et al., 2023c, ). While LLMs have significantly impacted text-based learning (e.g., Bewersdorff et al., 2023a ; Seßler et al., (2023); Küchemann et al., (2023)), the advent of MLLMs promises to extend these benefits to include visual, auditory, and other sensory data modalities.

Multimodal Large Language Models.
Building upon the foundation of LLMs, MLLMs are a further advancement considering their ability to process and generate content across various data types, including text, images, audio, and video (Bommasani et al.,, 2021). However, these models are built to understand, interpret, and respond to multiple modalities, enriching context information beyond merely text-based capabilities.
Much initial research focuses on the combination of visual and textual understanding as a multimodal input, yet they predominantly generate output in text form only (Alayrac et al.,, 2022; Zhu et al.,, 2023; Huang et al.,, 2023; Ye et al.,, 2023). To accomplish this joint understanding of textual and visual input, developers often integrate existing image encoders with pre-trained LLMs. They enable this combination by incorporating additional modules that project the different data forms into a shared embedding space (Li et al., 2023b, ; Liu et al.,, 2023; Zhang et al., 2023c, ).

However, the capabilities of MLLMs are not limited to images and text; they can also process combinations of text and video data (Li et al., 2023b, ; Maaz et al.,, 2023). For example, this can be achieved by dissecting video into audio and a series of images, then encoding and embedding each element separately to capture the context of the video format (Zhang et al., 2023c, ). Taking a more comprehensive approach, multimodal inputs can also move beyond mere dual-modality and include additional sensor data (Driess et al.,, 2023) or speech (Chen et al.,, 2023). An example of this advancement is PandasGPT (Su et al.,, 2023), which integrates six different modalities as input for LLMs.

Despite the proficiency of LLMs in processing multimodal context, they are currently mostly designed to output information solely in textual format. By combining visual foundation models (Wu et al., 2023a, ), audio foundation models (Huang et al.,, 2023), or both (Shen et al.,, 2023), LLMs can act as a sophisticated ’controller’ between data types. This allows them to intelligently invoke specific AI models as needed, marking a preliminary step toward generating multimodal outputs.

Enhancements in multimodal capabilities, such as more advanced structures for audio processing (Zhang et al., 2023a, ), have the potential to significantly boost performance. The concept of a singular model capable of handling text, images, audio, and video for both input and output is still relatively nascent.
Recently, Wu et al. published NExT-GPT as a general-purpose any-to-any open-source MLLM (Wu et al., 2023b, ) and OpenAI released GPT-4 Vision (OpenAI,, 2023) and GPT-4 Turbo111https://chatopenai.de/gpt-4-turbo/, marking an important further development in this research. Also, Google announced an new LLM-based AI system they named Gemini, which is, according to Google ”built from the ground up for multimodality - reasoning seamlessly across text, images, video, audio, and code” (DeepMind,, 2023). This kind of reasoning in combination with other types of deep learning and explainability approaches (Wu et al.,, 2020; Borisov et al., 2022a, ; Rombach et al.,, 2022) has the potential to advance science (Wong et al.,, 2023) and education. Often, these AI systems are labeled Multimodal Foundation Models (Li et al., 2023a, ). Following Fu et al., (2023), we will use the term ’Multimodal Large Language Models’ in our paper.

2.3. Adaptive Multimodal Learning

Human cognitive processing of information occurs through various channels, each handling different forms of information, such as spoken or written language or images. The insight that combining multiple modalities can enhance knowledge acquisition is documented in Mayer’s theory of multimedia learning (Mayer,, 1997, 2021) as well as in Schnotz & Bannert’s theory of text-picture integration (Schnotz and Bannert,, 2003). Based on cognitive models of information processing, such as Paivio’s Dual Coding Theory (Paivio,, 1991), the so-called multimedia effect is the well-supported hypothesis that active processing of both textual and pictorial information enhances integration into a coherent mental model (for a recent meta-analysis of the multimedia effect, see Hu et al., (2021)). Knowledge acquisition becomes more complete and less ambiguous and, thus, more effective when learners construct mental models from different modalities. Different representations can complement each other or even lead to a better overall understanding. For example, an image of a human skeleton or the depiction of an enzymatic reaction could be more effective and easier to understand than a written description, particularly when considering the time required to process the information. However, the verbal representation of knowledge can complement the image, especially when terms presented in text are unknown. Statements and deeper thoughts can also be represented visually, although not unambiguously.

According to the Cognitive Theory of Multimedia Learning (CTML), multimodal representation enables the selection, organization, and integration of learning content into a coherent mental model (Mayer,, 2021). Learners first select relevant information from the presented material to focus their attention on. The selected information is then organized in the learner’s mind into coherent structures, and finally, learners integrate the organized information with their existing knowledge to make sense of it. For instance, according to the signaling principle (cf. van Gog, (2014)), learners often have difficulty selecting important information in learning materials, so they need to be supported in their search to avoid unnecessary cognitive load, especially in text-image relations (for a meta-analysis of different studies on the signaling principle, see Richter et al., (2016)). Previous research has shown that signaling, i.e., separate selection aids, can hinder learning, especially for learners with at least sufficient prior knowledge (e.g., Richter and Scheiter, (2019)).

Second, learners have to organize their learning materials, i.e., text and images, according to their needs to keep their cognitive demands as low as necessary for efficient learning processes to take place (Mayer and Moreno,, 2003). Third, according to Mayer, (2021), the integration of multimodal representations requires generative activities on the part of the learner. It is, therefore, essential that multimodal representations are actively transformed into coherent mental models by the student.

As will be discussed below in relation to specific science education contexts, MLLMs offer a potential added value to this three-step process by enabling learners and educators to adapt multimodal representations themselves. As the CTML refers to the processing of multimodal information in the context of teaching-learning processes (cf. Mayer, (2021)), it provides a suitable conceptual framework for the following discussion of the potential of MLLMs in (science) education.

3. Applications of Multimodal LLMs for Science Education

The following chapter is structured by central aspects of science education (see 2.1). It aims to present exemplary potentials of MLLMs (see 2.3) in science teaching and learning, focusing specifically on adaptive, multimodal learning (see 2.4). The framework discussed in the remainder of this section is succinctly represented in  Table 1.

Subsection
Exemplary Aspects

3.1 MLLMs for Content Creation

- Tailoring multimodal learning materials to diverse student needs
- Organizing content effectively to reduce cognitive load
- Promoting active engagement through generative activities
- Flexible adaptation of visual representations for easier recognition (signaling)
- MLLM-based code and content generation for virtual reality environments
- Comprehensive integration of MLLMs into virtual reality settings via APIs

3.2 MLLMs for Supporting and Empowering Learning

3.2.1 Fostering Scientific Content Knowledge
- Transforming/supplementing text with visuals
3.2.2 Fostering the Uses of Scientific Language
- Assisting in understanding and using scientific language
- Simplifying technical language and explaining technical terms
3.2.3 Supporting Engagement in Scientific Practices
- Assisting in formulating research questions and hypotheses
- Visualizing and interpreting raw data
- Providing contextual explanations alongside visual representations.
3.2.4 Supporting Scientific Communication & Presentation

- Converting data structures for effective communication
- Generating image-based storyboards from analogies of scientific phenomena

3.3 MLLMs for Assessment and Feedback

3.3.1 Visual Assessment
- Personalized assessment of text and visual content in students’ reports
- Enhancing quality and objectivity of assessments
3.3.2 Multimodal Feedback
- Providing elaborated feedback with visual aids
- Instant feedback on various modalities like texts and drawings

Table 1. Exemplary aspects of the proposed framework for science education using MLLMs.

3.1. MLLMs for Content Creation

The development of learning materials is a central task for educators. These materials should be designed to meet the learners’ needs while keeping the learning goal(s) in mind. Multiple representations can foster student motivation, interest, and conceptual understanding (Treagust,, 2008). For example, a diagram can provide learners with a way of visualizing the concept and hence developing a mental model (Gabel,, 1998). The creation of effective learning materials, therefore, often entails a shift in the modality - especially when the educator has to cater materials to diverse learning groups. MLLMs can help educators create tailored, multimodal learning materials to meet the diverse needs of the students.

While more skilled students might work on plain tabular data, others might be served better with a diagram or even (additional) textual or auditive explanations. The educator could provide accompanying visual information to otherwise text-only knowledge representations. For example, this could be done to map certain habitats, give images of listed laboratory equipment, provide images of certain mammals or plants as well as provide structural animations of atoms and molecules. Using MLLMs, images can be flexibly adapted to make it easier for learners to directly recognize essential aspects of the visual representation (cf. signaling).

In addition, MLLMs can help organize learning content effectively, thereby reducing cognitive load, as Mayer and Moreno, (2003) suggested. The organization is crucial for creating materials that are accessible and understandable to a wide range of learners. For example teaching complex organic chemistry reactions, like the mechanism of SN1 and SN2 reactions, can be challenging due to their abstract nature. MLLMs could generate detailed, step-by-step visualizations of these mechanisms. Due to the adaptive nature of MLLMs, students can manipulate variables and see the effects on the reaction process.

Fostering engagement with such learning materials via MLLMs through generative activities, integrating multimodal representations (Mayer,, 2021), could even go further, shifting traditional content creation partially from the educator to the student: The student adaptively creates (organizes) his own learning materials based on an initial impulse, such as a textual description of the mechanism of SN1 and SN2 reactions - this can range from figures and diagrams to animations, or even synthetic datasets to investigate the chemical reaction.

Moreover, MLLM-based learning content can be integrated into innovative, immersive virtual-reality learning environments. The ability of MLLMs to reason about spatial relationships, coupled with their ability to generate relevant code and visual elements, facilitates their use in the design, creation, and extension of virtual environments. In addition, well-defined application programming interfaces (APIs) to MLLMs allow for a comprehensive integration of MLLMs into these virtual settings (see Hartmann et al., (2023)).

3.2. MLLMs for Supporting and Empowering Learning

3.2.1. Fostering Scientific Content Knowledge

Engagement in real-world science materials is key to an authentic learning experience. Authentic learning can help boost motivation (Banas and York,, 2014) and science understanding (Nathan and Sawyer,, 2014). Learning with real-world materials, like research papers or even Wikipedia articles, implies they were not originally designed (primarily) for learning; many original scientific sources are predominantly text-based.

MLLMs can enhance these materials by transforming or supplementing textual information with visual models, thereby aiding students in visualizing complex scientific concepts and increasing the accessibility of original sources. This gives students the opportunity to engage with real-world materials of their choice.
For example, students try to understand the function of an insect’s eye based on an image they found on Wikipedia. MLLMs could help students to adaptively interact with these materials and complement text-based information (Figure 1) based on their background and prior knowledge. As exemplarily depicted in Figure 1, the MLLM is capable of analyzing the image and providing adaptive information tailored to the competency of the learner (i.e., grade 5 and grade 12 student).

Figure 1. Example of fostering scientific content knowledge: Graphical representation of an insect’s eye uploaded to an MLLM (ChatGPT with GPT4-Vision, (OpenAI,, 2023)) asking for explanatory information for a 5th as well as a 12th grade student.

It is well known in previous works in education research that learners often face difficulties in understanding and interpreting diagrams (Henderson,, 1999). Therefore, it is crucial to keep learners’ cognitive demands as low as necessary for efficient learning processes to take place (Mayer and Moreno,, 2003) and further to keep the text and image information understandable for the learner (cf. “pretraining principle”; e.g., Jung et al., (2019)). In this context, MLLMs could assist in the reception and understanding of diagrams, making complex data more accessible. This could be achieved by augmenting the diagram with textual explanations on the level of the diagram itself, like the explanation of the labels of the axis or even textualizing the presented data.

3.2.2. Fostering the Uses of Scientific Language

Learning scientific language is a major aspect of science education (Wellington and Osborne,, 2001; Nielsen,, 2012). But non-scientists, like students, often find scientific language to be severely limiting and difficult (Gardner,, 2012). From the perspective of multimedia learning, it is essential that the text and image information is understandable to the learner (Jung et al.,, 2019). MLLMs could be used in this context to help students recall and remember scientific terms in images or diagrams. Using MLLMs, learners can adaptively augment verbal information like technical language, or have technical terms explained on the fly, for example, from a scientific podcast.

3.2.3. Supporting Engagement in Scientific Practices

Engaging in scientific practices, such as modeling or planning and executing experiments, are central components of science curricula in Germany (KMK,, 2004) and around the world (e.g., US: NRC, (2012), UK: Department for Education, (2013), and globally: OECD, (2018)). MLLMs have the potential to assist students in various scientific practices, from generating ideas and models to interpreting diagrams and guiding investigations.

When confronted with a scientific problem, students often struggle to formulate adequate research questions eligible for scientific investigation (Neber and Anton,, 2008; Hofstein et al.,, 2005). MLLMs can inspire students to think about potential scientific questions and help in the process of formulating adequate hypotheses. For example, an educator could provide an image of an eclipse, asking students to formulate questions they want to investigate. If some students struggle to develop adequate hypotheses on their own, the educator has to provide appropriate scaffolds like providing more images, some complementary textual information, or motion graphics like videos and animations of the eclipse to prevent stagnation in the students’ scientific investigation. MLLMs could help generate appropriate scaffolds in different modalities on-the-fly. Equipped with tailored scaffolds, it still remains up to the educator to choose the appropriate degree of guidance.

Furthermore, visualizing and interpreting raw, unstructured data often challenges many students (e.g., von Kotzebue et al., (2014); Setiawan and Sukoco, (2021)). MLLMs have the capability to render raw data into diagrams. Furthermore, MLLMs could significantly enhance understanding by explaining the key properties of the visualized data. These properties might include information about the x- and y-axes, underlying mathematical functions, or special points of interest within the data. MLLMs can provide tailored support by potentially shifting or adding another modality to the mathematical or data level, facilitating thus a deeper understanding. Moreover, they can assist in interpreting the data or drawing conclusions, thereby aiding in a comprehensive understanding of the data’s significance. By providing contextual explanations alongside visual representations, MLLMs can bridge the gap between raw data and meaningful interpretation, aiding not only in comprehension but also in deriving interpretations and conclusions from the data.

Engaging with specialized laboratory equipment is an essential aspect of students’ scientific inquiry processes, but instructions often refer to laboratory equipment in technical terms. Additionally, students sometimes also have difficulties with properly handling measuring and laboratory equipment (Kechel,, 2016). In this context, MLLMs can offer images of unknown instruments, preventing thus misuse and confusion. Beyond the static augmentation of names of laboratory equipment by explanatory images, MLLMs hold the potential to guide students during the use of laboratory equipment. By capturing photos of laboratory equipment with devices like smartphones or tablets and detailing the issues faced during operation, MLLMs can effectively guide students through the process, adapting responsively to their needs (see Figure 2).

Figure 2. Example of fostering scientific practices: Students can ask about which steps to perform in an inquiry by uploading the given material (here, ChatGPT with GPT4-V (OpenAI,, 2023) was used).

Note-taking is crucial for the success of scientific inquiry, yet it can be a complex task. To be successful, students first need a basic understanding of what and how to write down their notes (MacNeil and Falconer,, 2010), which draws attention and ultimatively cognitive load during the process of scientific inquiry. MLLMs can help by transcribing spoken words into text summaries, which aids in note-taking without drawing any attention and cognitive capacities away from the scientific inquiry. The reduction of cognitive load might be beneficial, especially for introductory science courses.

All these examples demonstrate the variety of how MLLMs can be employed in scientific practices, always aligning with basic multi-modal learning theories: multimodal aids can help students grasp complex scientific concepts and formulate relevant questions, which aligns with Mayer, (2021) and Schnotz and Bannert, (2003) theories on the integration of text and images, facilitating the construction of mental models from different representations. For instance, the assistance in the proper use of laboratory equipment by providing images and explanatory content aligns with the call for effective organization of learning materials by Mayer and Moreno, (2003). Transcription assistance is a practical application of the signaling principle, potentially reducing the cognitive load on students and aiding in the efficient organization of information.

3.2.4. Supporting Scientific Communication & Presentation

Communication of scientific results and ideas is a central aspect in science curricula (Department for Education,, 2013; NRC,, 2012; KMK,, 2004). For students to proficiently convey and articulate scientific concepts, they must generate new content. Therefore, it is important that they actively integrate new information with their pre-existing knowledge to make sense of and create their content (Mayer,, 2021). This integration of multimodal representations requires generative activities like creating diagrams from data by the student. MLLMs can assist in this process by converting data structures, such as tabular data, into diagrams, animations, or graphics, and transforming graphics into text, thereby supporting the process of creating content for scientific communication. One example is provided in Figure 3 where a shift from tabular data to a diagram and, finally, textual data is demonstrated.

Figure 3. Example of supporting students’ scientific presentations: Students can adaptively use their tabular data to create diagrams and then generate explanatory text based on these diagrams.

Another example is the adaptive generation of complete image-based storyboards building on given analogies of scientific phenomena, as demonstrated by Cao et al., (2023) (example: ibidem). In this process, firstly, abstract scientific concepts are translated into relatable text-based analogies to simplify understanding; secondly, these analogies are further converted into static visual representations to enhance conceptual clarity; and finally, these static visuals are evolved into dynamic visual analogies, offering dynamic representations.

3.3. MLLMs for Assessment and Feedback

3.3.1. Visual Assessment

Assessment is crucial for successful learning trajectories (Hattie,, 2008; Hattie and Timperley,, 2007). Especially forms of (computer-based) ‘rapid formative assessment’ have shown to be highly effective (Yeh,, 2010).

Visual representations in science education encompass a wide variety of elements, including, but not limited to, mathematical graphs, diagrams, figures illustrating models and processes, as well as students’ sketches from experiments. They serve as various channels to convey and assimilate scientific ideas. However, there is a noticeable lack of using the full potential of assessing these visual representations. This primarily stems from the substantial time and effort required on the part of educators to evaluate these often very complex, incomplete, or even contradictory visual constructs.

There are already many tools that use LLMs to provide assessment in science education, e.g., Bewersdorff et al., 2023a ; Zhai, (2023); Latif and Zhai, (2023). All of these mentioned assessment tools provide textual information based on textual input; they are uni-modal. Therefore, the ways of assessment are limited, especially in science education, with their predominant multimodal representations. MLLMs can deliver on any modality, enhancing the possibilities of assessment.

Students often create written reports on an experiment, including drawings of their experimental setup. MLLMs, with their capability to assess text and visual content like graphs and diagrams, could provide a comprehensive, personalized assessment of their written reports, ultimately providing a deeper understanding of students’ cognitive processes and their skill in conveying complex science in both written and visual modes. Besides analyzing students’ cognitive processes by using MLLMs for assessment, educators could potentially save time and enhance both the quality and objectivity of assessments. Lee and Zhai, (2023) demonstrated an AI system assessing drawn models of scientific phenomena, pioneering new ways of visual assessment.

3.3.2. Multimodal Feedback

Feedback, especially if elaborated and not only providing the correct answer, has been shown to be highly effective for students’ learning (Van der Kleij et al.,, 2015). Building on successful uni- or multimodal assessment, feedback can make student learning more effective. As with assessment, current feedback tools are mostly text-based e.g., Seßler et al., (2023) and, therefore, might not use their full potential to provide effective feedback in science education. With regard to CTML (Mayer,, 2021), multimodal feedback, combining visual and auditory elements, engages ideally dual-channel cognitive processing of learners. This integration not only balances cognitive load but also enhances comprehension and retention, ultimately fostering understanding.

Students could receive feedback complemented by visual aids for their textual work. For example, visual representations like models of atoms, molecules, and their reactions could be provided to students describing a chemical reaction, helping them clarify misconceptions. Due to the responsiveness of MLLMs, these figures do not have to be stored and manually annotated to the particular misconceptions as in common, non-MLLM-based feedback tools.

The design of feedback should always be considered in relation to subsequent related tasks (Henderson et al.,, 2019). MLLMs possess the capability to provide almost instant feedback, not only on student texts but also on other modalities like their drawings. This immediate response enables students to promptly adjust their work, thereby preventing them from pursuing ineffective approaches that could halt their learning process.

4. Challenges and Risks of MLLMs in Science Education

While the adaptability of MLLMs in science education is promising, it is essential to approach their potential with caution. The allure of providing students with extensive flexibility in choosing the desired modalities within their learning environment can be strong. However, evidence suggests that minimal guidance in science education may not always yield optimal learning outcomes (Kirschner et al.,, 2006; Sweller et al.,, 2007). Learners might require guidance in selecting the most appropriate modality to enhance their educational experience effectively. An abundance of options can not only serve as a distraction, but can also elevate the overall cognitive load, potentially hindering the learning process. This is especially true for students with low self-regulation capabilities (Lan,, 1998; Ley and Young,, 1998). Consequently, the roles of educators remain pivotal in guiding the learning process (Ley and Young,, 2001). They play a critical role in facilitating the effective use of these advanced tools, ensuring that the technology enhances, rather than impedes, the learning experience. In this context, the nuanced integration of MLLMs calls for a balanced approach, where the technology is leveraged thoughtfully to complement and augment traditional educational practices rather than replace them outright.

Students should engage in scientific practices in problem-based learning and open inquiries. But as highlighted in As minimal guidance can hinder effective learning in science education (Kirschner et al.,, 2006; Sweller et al.,, 2007) MLLMs should be designed to be adjustable by the educator to the individual student’s competency level. In this way, MLLMs would be able to provide degrees of guidance or scaffolding rather than acting as a personalized, adaptive, and multimodal agent that provides immediate answers and solutions. This mediated approach could encourage students to engage in critical thinking and problem-solving, fostering a deeper understanding and promoting self-directed learning without overexerting the student. The MLLMs should be aligned with educational and instructional strategies that prioritize the development of students’ analytical skills in tandem with their knowledge acquisition.

Ethical considerations encompass the moral and ethical implications of using MLLMs, including issues of bias, privacy, consent, and the overall impact on the quality and equity of education. MLLMs sometimes still generate biased (Venkit et al.,, 2023) incorrect, faulty or fabricated content (often referred to as hallucinations) (Ji et al., 2023b, ; Zhang et al., 2023b, ; Azamfirei et al.,, 2023; Manakul et al.,, 2023), particularly in the context of logical and mathematical reasoning (Imani et al., 2023b, ). Therefore, it is crucial for researchers to empirically examine the potential bias that may contaminate assessment validity (Zhai and Nehm,, 2023). Research has already shown evidence that AI has the potential to enlarge the score divergence by gender or English language proficiency (Latif et al.,, 2023; Wilson et al.,, 2023). Educators need to be aware of these limitations, as well as over-blow of AI bias (e.g., pseudo AI bias, see (Zhai and Krajcik,, 2022)). Moreover, if students are encouraged to use MLLMs independently, it is essential that educators communicate these types of potential flaws to them. Fostering a culture of ethical data handling among educational stakeholders, alongside creating awareness about the potential risks and safeguards among the student populace, is crucial to ensure a secure and responsible utilization of MLLMs in educational settings.

With AI becoming an increasingly integral part of our daily lives, policymakers have begun to implement policies to regulate and safeguard AI development and its use in education (Schiff et al.,, 2020). E.g., the currently presented so-called European AI Act (European Union, (2023)) requires generative AI systems, such as MLLMs, to disclose when content is AI-generated, design models to prevent the generation of illegal content, and publish summaries of copyrighted data used for training. The use of such AI systems, and therefore MLLMs, in education will be classified as high-risk applications and will require registration in an EU database. On every level of deploying MLLMs, all stakeholders, such as developers, educators, administrators, and policymakers, as well as the corresponding governance framework, have to prioritize ethical and regulatory considerations.

Educators and learners have a variety of pre- and misconceptions, fears, and hopes about AI (Bewersdorff et al., 2023b, ), which might lead to general skepticism toward AI systems in the classroom among stakeholders (Douali et al.,, 2022), ultimately hindering its effective implementation. For effective implementation, policymakers do not only have to ensure that all learners and educators have access to these potentially powerful tools for learning - they have to provide them with knowledge about AI (AI literacy: Long and Magerko, (2020); Hornberger et al., (2023)) and the competencies they need to successfully employ these AI systems.

Looking forward, there are also risks associated with proprietary MLLMs, such as unknown ethical considerations and implementations. Hence, the decision between open-source and proprietary MLLMs becomes pivotal in the long term. While proprietary models may offer robust data security and professional support, they often come with limitations in terms of accessibility, customization, and cost. This could hinder collaborative learning and innovation, as proprietary MLLMs might not be as adaptable or transparent as their open-source counterparts. Moreover, through restrictions in the ability to tailor proprietary models to specific educational contexts, such models might not always align with the diverse needs of educators, learners, researchers, or other stakeholders. As technology advances, the choice between open-source and proprietary MLLMs may not only be decisive for the trajectory of adoption of generative AI in education but also the realization of an inclusive, digitally advanced educational landscape.

5. Discussion and Conclusion

LLMs have emerged as a transformative force in the field of education (Abdelghani et al., 2023b, ; Ji et al., 2023a, ; MacNeil et al.,, 2022). The integration of MLLMs in science educational settings holds the promise of personalized and adaptive learning experiences, matching the needs of learners by delivering content that is both accessible and engaging.

MLLMs are characterized by their ability to analyze and interpret data from different sources, such as spoken language, written text, or images. A key advantage of MLLMs over static sources of information, such as textbook representations, is the adaptive nature of these models. Both educators and students can use MLLMs to independently transform information into other modalities, such as textual information on the evolution of ant populations, into visual representations. This capability of MLLMs can be called ”adaptive transformation.” It allows knowledge representations to alter form flexibly, especially between text and images, but also within a modality, for example, to simplify complex images or make difficult text more understandable. This shows that MLLMs can change and adapt knowledge representations almost limitlessly and with great efficiency. The question is how this can be used to foster knowledge acquisition and scientific competencies.

One central question is how MLLMs and the advantages of ”adaptive transformation” can ultimately support multimedia learning, i.e., the integration of different knowledge representations into an integrated mental model. Focusing on the three stages of multimodal learning (Mayer,, 2021; Schnotz and Bannert,, 2003), MLLMs can play a crucial role in every stage. MLLMs and the potential of ”adaptive transformation” might help learners perform these three-step cognitive processes of selection, organization, and integration.

Whereas in the past, support had to be provided by the learning material or the educator, it is now possible for learners to generate such support adaptively. For example, with MLLMs it is possible for learners to summarize texts, highlight important text passages, or display similarities between related texts and images as key points. In addition, an adaptive use of MLLMs would allow learners to integrate selection aids into multimodal representations only when they need them. This would make it possible to avoid expertise reversal effects (Kalyuga,, 2007).

A problem with employing MLLMs for (self-directed) learning might be that learners require a high degree of self-regulatory skills (e.g., Bannert et al., (2014)) in order to effectively and constructively use MLLMs for learning purposes.
As mentioned earlier, learners can effectively use MLLMs to integrate multimodal learning materials, as MLLMs allow learners to select, organize, and integrate learning materials according to their needs from multimodal sources. This improves the overall access to as well as the preparation of the learning material. In addition, multimodal representations have the potential to help learners better grasp the concepts to be learned. For example, if learners are unable to understand complex texts or associate complex schematic representations, MLLMs can be used to adapt learning materials so that integration is possible.
It is necessary to use MLLMs in a way that the generative activities are not completely absorbed by the AI, but proportionally also by the learners. Regulating this balance seems to be a central pedagogical challenge when using MLLMs in education.

Science learning is multimodal, requiring students to engage with a variety of information formats like diagrams, tabular data, natural-language texts, images, and animations and synthesize information as well as shift across various formats (Van Leeuwen and Kress,, 1990; Doran et al.,, 2021). A lack of representational competency can hinder science learning (Nitz et al.,, 2014).
With the emergence of MLLMs, educators now have new potential tools to address the necessity for multimodality in science education. MLLMs are equipped to process and generate multimodal content for different levels of competency. This capability is crucial in a discipline where understanding often hinges on the ability to interpret complex diagrams, analyze diverse datasets, and synthesize information from multiple sources. With MLLMs, there is potential for enhanced guidance and support in both mastering individual modalities and transitioning fluidly between them.

In summary, MLLMs can support learners in exploiting the potential of multimodal learning materials and presentations. In particular, through adaptive design options, either by the learners themselves or by the educators in advance, it is possible to support learners in the selection, organization and integration of information contained in text, images or other modalities. This adaptivity makes learning processes potentially more effective. For example, learners with a lot of prior knowledge on a specific topic can choose more complex representations, while learners with fewer skills can adapt learning materials to their needs. However, this also highlights the difficulty of regulating the effective use of MLLMs, either by the learners themselves or by the scripted use of AI-based applications to enable generative learning processes on the part of the learners. These issues provide an area for future research and numerous potential applications.

6. Future Implications

MLLMs could take the advantages of multimodal learning environments to the next level. Unlike conventional settings, such as hypertext environments, MLLMs offer a superior degree of interactivity, enabling thus a more dynamic and engaging learning experience.

One of the most notable advantages of MLLMs is their ability to swiftly transition between different modes upon request, a feature not typically feasible in traditional multimedia learning environments. This capability paves the way for highly individualized learning experiences, tailored to the unique needs and preferences of each learner. By combining the strengths of LLMs — such as interactivity and real-time generation of content — with the efficiency of multimodal learning in optimizing cognitive resource usage, MLLMs offer new ways to support learning.
Furthermore, MLLMs facilitate a seamless transition between learning modes, potentially enhancing thus the representational competencies of learners, which are crucial for a deep understanding of scientific concepts (Nitz et al.,, 2014). This seamless integration of different modalities can significantly improve the learning process.

The potential shift towards more responsive and personalized learning environments, as facilitated by MLLMs, represents a significant advancement in educational technology. This shift could lead to learning environments that are more attuned to the individual needs of students, thereby enhancing the overall learning experience.

As MLLMs are still in their infancy, there is a need for further research, which should not only investigate the various potentials from personalized learning to inclusiveness and the ones mentioned in this article. It is also crucial to focus on the potential (further) shift of the educator’s role. As AI systems become multimodal, they potentially become more advanced, making it relevant to re-think and continuously re-evaluate the educator’s role. It is crucial to understand that MLLMs, like any other AI system, should not replace the educator or, worse, be seen as competitors, but that MLLMs may alter the educators’ role in the learning process (Burbules et al.,, 2020; Schiff,, 2020). The educators’ role changes depending on the degree of automation. Different modes and degrees of implementation of AI systems are imaginable (Molenaar,, 2022). However, the impact of MLLMs will not be limited to science education; for other disciplines, there seem to be analogous opportunities and challenges (cf. Lee et al., 2023a ).

In light of these considerations, it becomes evident that the integration of MLLMs into educational frameworks across various disciplines necessitates a thoughtful and collaborative approach, where the evolving role of educators is recognized and supported, ensuring that these advanced technologies enhance, rather than overshadow, the human-centric aspect of teaching and learning.

---

Now, take a deep breath and write a blog post about this paper.
